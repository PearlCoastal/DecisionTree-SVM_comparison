{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparison_DecisionTree_SVM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOvdjJtOXYgRtRoEydhCOX3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PearlCoastal/Machine-Learning/blob/master/Comparison_DecisionTree_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUHcBTv-SSbZ"
      },
      "source": [
        "#Here are my source code and discussion under the results compared between Decision Tree and SVM.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "n55snSV7SWIS",
        "outputId": "1579effd-b0ab-4e8e-b819-96a60bcb9660"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "#I am using the dataset named \"penguin\".\n",
        "\n",
        "#Using species island culumen and flipper to check whether the penguin is a male or a female\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\"\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# The initial dataset contains \"species\", \"island\" and \"sex\" which are string and I've transformed them into float using \"replace\"\n",
        "\n",
        "# First Step: Data pre-processing procedure\n",
        "\n",
        "# Like in species there are three kinds : \"Adelie, Chinstrap, Gentoo\", and they are in \"string\"so I replace it with \"0,1,2\" which is in \"float\"\n",
        "\n",
        "# The island and sex are pre-processed as the same\n",
        "\n",
        "# species\n",
        "df=df.replace({'Adelie' : 0, 'Chinstrap' : 1, 'Gentoo' : 2})\n",
        "\n",
        "# island\n",
        "df=df.replace({'Torgersen':0,'Dream':1,'Gentoo':2,'Biscoe':3})\n",
        "\n",
        "# sex\n",
        "df=df.replace({'MALE' : 0, 'FEMALE' : 1})\n",
        "\n",
        "\n",
        "# Because there are several missing values in penguin dataset as showing like \"NaN\"\n",
        "# so I use the dropna function in order to drop those missing indices.\n",
        "\n",
        "df.dropna(subset= ['sex'], inplace = True)\n",
        "\n",
        "df\n",
        "\n",
        "# here are my pre-processed dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>species</th>\n",
              "      <th>island</th>\n",
              "      <th>bill_length_mm</th>\n",
              "      <th>bill_depth_mm</th>\n",
              "      <th>flipper_length_mm</th>\n",
              "      <th>body_mass_g</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.1</td>\n",
              "      <td>18.7</td>\n",
              "      <td>181.0</td>\n",
              "      <td>3750.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.5</td>\n",
              "      <td>17.4</td>\n",
              "      <td>186.0</td>\n",
              "      <td>3800.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40.3</td>\n",
              "      <td>18.0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3250.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.7</td>\n",
              "      <td>19.3</td>\n",
              "      <td>193.0</td>\n",
              "      <td>3450.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39.3</td>\n",
              "      <td>20.6</td>\n",
              "      <td>190.0</td>\n",
              "      <td>3650.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>47.2</td>\n",
              "      <td>13.7</td>\n",
              "      <td>214.0</td>\n",
              "      <td>4925.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>46.8</td>\n",
              "      <td>14.3</td>\n",
              "      <td>215.0</td>\n",
              "      <td>4850.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>50.4</td>\n",
              "      <td>15.7</td>\n",
              "      <td>222.0</td>\n",
              "      <td>5750.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>45.2</td>\n",
              "      <td>14.8</td>\n",
              "      <td>212.0</td>\n",
              "      <td>5200.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>49.9</td>\n",
              "      <td>16.1</td>\n",
              "      <td>213.0</td>\n",
              "      <td>5400.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>333 rows Ã— 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     species  island  bill_length_mm  ...  flipper_length_mm  body_mass_g  sex\n",
              "0          0       0            39.1  ...              181.0       3750.0  0.0\n",
              "1          0       0            39.5  ...              186.0       3800.0  1.0\n",
              "2          0       0            40.3  ...              195.0       3250.0  1.0\n",
              "4          0       0            36.7  ...              193.0       3450.0  1.0\n",
              "5          0       0            39.3  ...              190.0       3650.0  0.0\n",
              "..       ...     ...             ...  ...                ...          ...  ...\n",
              "338        2       3            47.2  ...              214.0       4925.0  1.0\n",
              "340        2       3            46.8  ...              215.0       4850.0  1.0\n",
              "341        2       3            50.4  ...              222.0       5750.0  0.0\n",
              "342        2       3            45.2  ...              212.0       5200.0  1.0\n",
              "343        2       3            49.9  ...              213.0       5400.0  0.0\n",
              "\n",
              "[333 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "id": "FhEU3zEmScE6",
        "outputId": "90e31030-e502-4cf8-a93f-15dbc441c81d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# using 'species', 'island', 'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g' as training feature\n",
        "feature = df.loc[:,['species', 'island', 'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g']]\n",
        "\n",
        "# supervised machine learning\n",
        "\n",
        "# 'sex' as label\n",
        "target = df.loc[:,['sex']]\n",
        "\n",
        "\n",
        "# seperate dataset\n",
        "\n",
        "# training data and test data are divided as 8/10 and 2/10\n",
        "\n",
        "# random state\n",
        "\n",
        "x_feature, y_feature, x_target, y_target = train_test_split(feature, target, train_size=0.8, random_state=2)\n",
        "\n",
        "x_feature"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4a9be71fcc12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# using 'species', 'island', 'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g' as training feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'species'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'island'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'culmen_length_mm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'culmen_depth_mm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'flipper_length_mm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body_mass_g'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# supervised machine learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1039\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"display.max_seq_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"display.width\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                     raise KeyError(\n\u001b[0;32m-> 1316\u001b[0;31m                         \u001b[0;34m\"Passing list-likes to .loc or [] with any missing labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m                         \u001b[0;34m\"is no longer supported. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m                         \u001b[0;34mf\"The following labels were missing: {not_found}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Passing list-likes to .loc or [] with any missing labels is no longer supported. The following labels were missing: Index(['culmen_length_mm', 'culmen_depth_mm'], dtype='object'). See https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfm60YE0Se4a"
      },
      "source": [
        "print(\"I choosed Decision Tree and Supporting Vector Machine as my supervised Machine Learning methods\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVmKBlMhShXh"
      },
      "source": [
        "# Using Decison Tree\n",
        "# construct a tree as below\n",
        "\n",
        "from sklearn import tree\n",
        "\n",
        "print(\"Train the data using Decision Tree\")\n",
        "\n",
        "\n",
        "# entropy is the expected value of information amount\n",
        "# when entropy is high,its difficlut to seperate\n",
        "# while entropy is low, its good\n",
        "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
        "\n",
        "clf=clf.fit(x_feature, x_target)\n",
        " \n",
        "# Show the trained tree using plot function\n",
        "\n",
        "print(\"Decision Tree is like below\")\n",
        "\n",
        "tree.plot_tree(clf) \n",
        "\n",
        "predicted_DT = clf.predict(y_feature)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# confusion matrix\n",
        "confusion_matrix(y_target,predicted_DT)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBirGQamSjgT"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "\n",
        "print(\"Results of Decision Tree\")\n",
        "\n",
        "print('Accuracy = ', accuracy_score(y_target, predicted_DT))\n",
        "\n",
        "print('Precision = ', precision_score(y_target, predicted_DT))\n",
        "\n",
        "print('Recall = ', recall_score(y_target, predicted_DT))\n",
        "\n",
        "print('F1 score = ', f1_score(y_target, predicted_DT))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okNp5EjkSla1"
      },
      "source": [
        "# using SVM\n",
        "\n",
        "print(\"Train the data using SVM\")\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC()\n",
        "\n",
        "clf.fit(x_feature, x_target)\n",
        "\n",
        "predicted_SVM = clf.predict(y_feature)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_target,predicted_SVM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxAsLA1bSniJ"
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "print(\"Results of SVM\")\n",
        "\n",
        "print('Accuracy = ', accuracy_score(y_target, predicted_SVM))\n",
        "\n",
        "print('Precision = ', precision_score(y_target, predicted_SVM))\n",
        "\n",
        "print('Recall = ', recall_score(y_target, predicted_SVM))\n",
        "\n",
        "print('F1 score = ', f1_score(y_target, predicted_SVM))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfSPlx13Ssgc"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4IlNN0-DUjx"
      },
      "source": [
        "\n",
        "\n",
        "# Report\n",
        "---\n",
        "\n",
        "\n",
        "1.   **Discussion**\n",
        "  \n",
        "  Discison Tree is easily to interpret, and easily to be trained.\n",
        "\n",
        "  And because there are several missing values in 'penguin' dataset, and Decision Tree is good dealing with dataset with missing values.\n",
        "  \n",
        "  SVM are supervised models with associated learning algorithm that analyze data used for classification and regression analysis, based on the statistical learning framework.\n",
        "\n",
        "  An SVM model performe better when dealing with high-dimentional space dataset, but when dealing with datasets which are at same space and predicted to belong to a category based on the side of the gap on which they fall.\n",
        "\n",
        "  So as in my experiment when 'penguin' datasets are using an SVM model, the accuracy and F1-score are way lower than its in Decision Tree. \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "2. **Data Analysis**\n",
        "\n",
        "  As you can see the results above.\n",
        "\n",
        "  The Accuracy of Decision Tree is 0.9253731343283582\n",
        "\n",
        "  while the Accuracy of SVM is 0.6716417910447762\n",
        "\n",
        "  So Decision Tree is better than SVM in Accuracy.\n",
        "\n",
        "  And as the F1 score is a measure of a test's accuracy. \n",
        "It considers both the precision and the recall of the test to compute the score.\n",
        "\n",
        "  The F1 score of Decision Tree  =  0.9315068493150686\n",
        "\n",
        "  and the F1 score of SVM  =  0.7027027027027027\n",
        "\n",
        "  So under the dataset of penguin, Decison Tree performed better than SVM.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "3. **Result**\n",
        "\n",
        "  In conclusion, in my consideration, Decision tree performs better when dealing with datatsets with missing values while SVM is not.\n",
        "\n",
        "  And SVM performs better when dealing with high-dimentional space but 'penguin' is not, so the results of accuracy and F1-score are not as good as its in Decision Tree."
      ]
    }
  ]
}